{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Importing Libraries"],"metadata":{"id":"5gZtEOF-bqlC"}},{"cell_type":"code","source":["pip install meteostat"],"metadata":{"id":"2zVx-0RgslwZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733829251675,"user_tz":-60,"elapsed":12880,"user":{"displayName":"Naomi Cedeño Manrique","userId":"07623801168020297088"}},"outputId":"5e4c6767-90df-411d-c1d4-a07d3379c295"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting meteostat\n","  Downloading meteostat-1.6.8-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from meteostat) (2.2.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from meteostat) (2024.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from meteostat) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->meteostat) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->meteostat) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.16.0)\n","Downloading meteostat-1.6.8-py3-none-any.whl (31 kB)\n","Installing collected packages: meteostat\n","Successfully installed meteostat-1.6.8\n"]}]},{"cell_type":"code","source":["# Importing modules\n","\n","from pyspark import SparkContext\n","from pyspark.sql.types import StructType, StructField, DoubleType, StringType, TimestampType, IntegerType, DateType, FloatType\n","from pyspark.sql import SparkSession, Row\n","from pyspark.sql.functions import col, when, countDistinct\n","from pyspark.sql import SparkSession\n","\n","from datetime import datetime\n","\n","from meteostat import Daily, Stations\n","\n","from pyspark.sql.functions import regexp_replace\n","from pyspark.sql.functions import monotonically_increasing_id\n","from pyspark.sql.functions import udf\n","from pyspark.sql.functions import broadcast\n","from pyspark.sql.functions import count, sum, when\n","\n","import math"],"metadata":{"id":"nz7ROtM3sodx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Uploading"],"metadata":{"id":"i0MLb4Ihsx4S"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ka0luTuhtCli","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733831907297,"user_tz":-60,"elapsed":24559,"user":{"displayName":"Naomi Cedeño Manrique","userId":"07623801168020297088"}},"outputId":"5eec3b9d-0787-46b4-ae65-7da6c3bee92e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Colab Notebooks/Distributed Data Analysis and Mining/Project/data\""],"metadata":{"id":"IWaoAuqctG2A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession.builder \\\n","    .appName(\"DDAM\") \\\n","    .master(\"local[*]\") \\\n","    .config(\"spark.executor.memory\", \"8g\") \\\n","    .config(\"spark.driver.memory\", \"8g\") \\\n","    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n","    .getOrCreate()"],"metadata":{"id":"MU0DZ5nftHaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gptS7Go-03dJ"},"outputs":[],"source":["# Create DataFrames an infer the schemas\n","\n","df_flights = spark.read.csv(path + '/2018.csv', header = True, inferSchema = True)\n","df_airports = spark.read.csv(path + '/airports.csv', header = True, inferSchema = True)\n","df_population = spark.read.csv(path + '/population by cities.csv', header = True, sep = ';')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pusTM6D3nNWb"},"outputs":[],"source":["df_population = df_population.withColumn(\"pop_2018\", regexp_replace(col(\"pop_2018\"), \",\", \"\")) \\\n","                           .withColumn(\"pop_2018\", col(\"pop_2018\").cast(\"integer\")) # Replace commas in 'pop_2018' with empty strings and cast to integer\n","\n","df_population = df_population.withColumn(\"city\", regexp_replace(col(\"city\"), \" city\", \"\")) # Remove \" city\" from the \"city\" column in df_population\n","\n","df_population = df_population.withColumnRenamed(\"city\", \"city_orig\") \\\n","                             .withColumnRenamed(\"state\", \"state_orig\") # Rename columns for join consistency"]},{"cell_type":"markdown","source":["## Joining Datasets"],"metadata":{"id":"KV1PoFctuw3_"}},{"cell_type":"code","source":["# Select specific columns from df_airports\n","\n","df_airports_selected = df_airports.select(\"code\", \"latitude\", \"longitude\", \"city\", \"state\")"],"metadata":{"id":"UrWgUgD1u057"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Airports"],"metadata":{"id":"2vJa5Pj3iGEF"}},{"cell_type":"code","source":["# Perform the first left join (BY ORIGIN)\n","\n","df = df_flights.join(df_airports_selected, df_flights.ORIGIN == df_airports_selected.code, \"left\") \\\n","    .drop(df_airports_selected.code) \\\n","    .withColumnRenamed(\"latitude\", \"latitude_origin\") \\\n","    .withColumnRenamed(\"longitude\", \"longitude_origin\") \\\n","    .withColumnRenamed(\"city\", \"city_origin\") \\\n","    .withColumnRenamed(\"state\", \"state_origin\")"],"metadata":{"id":"39MHyiI5u3Ma"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform the second left join (BY DESTINATION)\n","\n","df = df.join(df_airports_selected, df.DEST == df_airports_selected.code, \"left\") \\\n","    .drop(df_airports_selected.code) \\\n","    .withColumnRenamed(\"latitude\", \"latitude_dest\") \\\n","    .withColumnRenamed(\"longitude\", \"longitude_dest\") \\\n","    .withColumnRenamed(\"city\", \"city_dest\") \\\n","    .withColumnRenamed(\"state\", \"state_dest\")"],"metadata":{"id":"K83kMp0Jh_Hq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Population"],"metadata":{"id":"xG0tlpUxiLvY"}},{"cell_type":"code","source":["df = df.join(df_population, [\"city_orig\", \"state_orig\"], \"left\") \\\n","    .drop(df_population.city_orig) \\\n","    .drop(df_population.state_orig) \\\n","    .withColumnRenamed(\"pop_2018\", \"population_origin_ok\")"],"metadata":{"id":"kzi2bEEzvWs7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Renaming and Adding Variables"],"metadata":{"id":"Owi_CPxX1O8N"}},{"cell_type":"code","source":["# Define the Haversine distance, which the greatest circle distance between two points on the Earth\n","\n","def haversine_distance(lat1, lon1, lat2, lon2):\n","    lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2]) # Map to radians\n","\n","    dlon = lon2 - lon1\n","    dlat = lat2 - lat1\n","    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n","    c = 2 * math.asin(math.sqrt(a))\n","    r = 6371\n","\n","    return c * r # Haversine formula\n","\n","haversine_udf = udf(haversine_distance, DoubleType())"],"metadata":{"id":"y3pJEQel01zu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply Haversine distance to the data frame\n","\n","df = df.withColumn(\n","    \"distance_km\",\n","    haversine_udf(\n","        col(\"latitude_origin\"),\n","        col(\"longitude_origin\"),\n","        col(\"latitude_dest\"),\n","        col(\"longitude_dest\")\n","    )\n",")"],"metadata":{"id":"Jw4sVu5gjqjv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create delaying column\n","\n","df = df.withColumn(\n","    \"Delayed_status\",\n","    when(df[\"ARR_DELAY\"] > 15, 1).otherwise(0)\n",")"],"metadata":{"id":"noiP47qP1BIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Renaming columns\n","\n","df = df \\\n","    .withColumnRenamed(\"FL_DATE\", \"Flight_Date\") \\\n","    .withColumnRenamed(\"OP_CARRIER\", \"Operating_Carrier\") \\\n","    .withColumnRenamed(\"OP_CARRIER_FL_NUM\", \"Flight_Number\") \\\n","    .withColumnRenamed(\"ORIGIN\", \"Origin_Airport\") \\\n","    .withColumnRenamed(\"DEST\", \"Destination_Airport\") \\\n","    .withColumnRenamed(\"CRS_DEP_TIME\", \"Scheduled_Departure_Time\") \\\n","    .withColumnRenamed(\"DEP_TIME\", \"Actual_Departure_Time\") \\\n","    .withColumnRenamed(\"DEP_DELAY\", \"Departure_Delay_Minutes\") \\\n","    .withColumnRenamed(\"TAXI_OUT\", \"Taxi_Out_Time\") \\\n","    .withColumnRenamed(\"WHEELS_OFF\", \"Takeoff_Time\") \\\n","    .withColumnRenamed(\"WHEELS_ON\", \"Landing_Time\") \\\n","    .withColumnRenamed(\"TAXI_IN\", \"Taxi_In_Time\") \\\n","    .withColumnRenamed(\"CRS_ARR_TIME\", \"Scheduled_Arrival_Time\") \\\n","    .withColumnRenamed(\"ARR_TIME\", \"Actual_Arrival_Time\") \\\n","    .withColumnRenamed(\"ARR_DELAY\", \"Arrival_Delay_Minutes\") \\\n","    .withColumnRenamed(\"CANCELLED\", \"Flight_Cancelled\") \\\n","    .withColumnRenamed(\"CANCELLATION_CODE\", \"Cancellation_Reason_Code\") \\\n","    .withColumnRenamed(\"DIVERTED\", \"Flight_Diverted\") \\\n","    .withColumnRenamed(\"CRS_ELAPSED_TIME\", \"Scheduled_Flight_Duration\") \\\n","    .withColumnRenamed(\"ACTUAL_ELAPSED_TIME\", \"Actual_Flight_Duration\") \\\n","    .withColumnRenamed(\"AIR_TIME\", \"Airborne_Time\") \\\n","    .withColumnRenamed(\"DISTANCE\", \"Flight_Distance\") \\\n","    .withColumnRenamed(\"CARRIER_DELAY\", \"Carrier_Delay_Minutes\") \\\n","    .withColumnRenamed(\"WEATHER_DELAY\", \"Weather_Delay_Minutes\") \\\n","    .withColumnRenamed(\"NAS_DELAY\", \"NAS_Delay_Minutes\") \\\n","    .withColumnRenamed(\"SECURITY_DELAY\", \"Security_Delay_Minutes\") \\\n","    .withColumnRenamed(\"LATE_AIRCRAFT_DELAY\", \"Late_Aircraft_Delay_Minutes\")"],"metadata":{"id":"KpBvTJ7S1YK0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Weather"],"metadata":{"id":"AvWPuBo2wfMT"}},{"cell_type":"code","source":["# Drop duplicates based on the origin airports data\n","\n","df_unique = df.dropDuplicates(subset=['latitude_orig', 'longitude_orig', 'Flight_Date']) \\\n","    .select(['latitude_orig', 'longitude_orig', 'Flight_Date'])"],"metadata":{"id":"uV_-U9qtwhSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get weather data\n","\n","def fetch_weather(row):\n","    try:\n","        lat, lon, date = row.latitude_orig, row.longitude_orig, row.Flight_Date # Extract coordinates and dates\n","        date_obj = date if isinstance(date, datetime) else datetime.strptime(str(date), \"%Y-%m-%d\") # Cast date to DateType\n","\n","        tavg = wspd = wdir = pres = 0.0 # Initializing weather variables\n","\n","        stations = Stations().nearby(lat, lon) # Get nearest station\n","        station = stations.fetch(1)\n","\n","        if not station.empty:\n","            data = Daily(station, date_obj, date_obj).fetch()\n","            if not data.empty:\n","                tavg = float(data.iloc[0].get(\"tavg\", 0.0))\n","                wspd = float(data.iloc[0].get(\"wspd\", 0.0))\n","                wdir = float(data.iloc[0].get(\"wdir\", 0.0))\n","                pres = float(data.iloc[0].get(\"pres\", 0.0)) # Retrieve data from stations\n","\n","        return Row(latitude = float(lat),\n","                   longitude = float(lon),\n","                   date = date_obj.date(),\n","                   tavg = tavg,\n","                   wspd = wspd,\n","                   wdir = wdir,\n","                   pres = pres\n","        ) # Create and return a row with weather data\n","    except Exception as e:\n","        print(f\"Error fetching data for row {row}: {e}\")\n","\n","        return Row(latitude = float(lat) if lat else 0.0,\n","                   longitude = float(lon) if lon else 0.0,\n","                   date = date_obj.date() if date_obj else None,\n","                   tavg = 0.0,\n","                   wspd = 0.0,\n","                   wdir = 0.0,\n","                   pres = 0.0\n","        ) # In case of error, return a row full of zeros"],"metadata":{"id":"H5xhp2Hqwrjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weather_rdd = df_unique.rdd.map(fetch_weather) # Get weather into an RDD\n","\n","weather_schema = StructType([\n","    StructField(\"latitude\", DoubleType(), True),\n","    StructField(\"longitude\", DoubleType(), True),\n","    StructField(\"date\", DateType(), True),\n","    StructField(\"tavg\", DoubleType(), True),\n","    StructField(\"wspd\", DoubleType(), True),\n","    StructField(\"wdir\", DoubleType(), True),\n","    StructField(\"pres\", DoubleType(), True),\n","]) # Build a schema for the data frame\n","\n","weather_df = spark.createDataFrame(weather_rdd, schema = weather_schema) # Create a dataframe from retrieved data"],"metadata":{"id":"9omLhMyBkrAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Join origin weather to main dataframe\n","\n","weather_df = weather_df.withColumnRenamed(\"tavg\", \"tavg_orig\") \\\n","                              .withColumnRenamed(\"wspd\", \"wspd_orig\") \\\n","                              .withColumnRenamed(\"wdir\", \"wdir_orig\") \\\n","                              .withColumnRenamed(\"pres\", \"pres_orig\") \\\n","                              .withColumnRenamed(\"latitude\", \"latitude_orig\") \\\n","                              .withColumnRenamed(\"longitude\", \"longitude_orig\") \\\n","                              .withColumnRenamed(\"date\", \"Flight_Date\") # Rename columns for joining origin data\n","\n","df = df.join(broadcast(weather_df),\n","             on = [\"latitude_orig\", \"longitude_orig\", \"Flight_Date\"],\n","             how = \"left\")"],"metadata":{"id":"YoQ-veH2quGz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Join destination weather to main dataframe\n","\n","weather_df = weather_df.withColumnRenamed(\"tavg_orig\", \"tavg_dest\") \\\n","                            .withColumnRenamed(\"wspd_orig\", \"wspd_dest\") \\\n","                            .withColumnRenamed(\"wdir_orig\", \"wdir_dest\") \\\n","                            .withColumnRenamed(\"pres_orig\", \"pres_dest\") \\\n","                            .withColumnRenamed(\"latitude_orig\", \"latitude_dest\") \\\n","                            .withColumnRenamed(\"longitude_orig\", \"longitude_dest\") # Rename columns for joining destination data\n","\n","df = df.join(broadcast(weather_df),\n","             on = [\"latitude_dest\", \"longitude_dest\", \"Flight_Date\"],\n","             how = \"left\")"],"metadata":{"id":"wEX52xI6x5fq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Final Schema"],"metadata":{"id":"-s6rY2vT1vWX"}},{"cell_type":"code","source":["df = df.withColumn(\"Flight_Date\", col(\"Flight_Date\").cast(DateType()))\n","df = df.withColumn(\"Flight_Number\", col(\"Flight_Number\").cast(IntegerType()))\n","df = df.withColumn(\"Scheduled_Departure_Time\", col(\"Scheduled_Departure_Time\").cast(IntegerType()))\n","df = df.withColumn(\"Actual_Departure_Time\", col(\"Actual_Departure_Time\").cast(IntegerType()))\n","df = df.withColumn(\"Departure_Delay_Minutes\", col(\"Departure_Delay_Minutes\").cast(IntegerType()))\n","df = df.withColumn(\"Taxi_Out_Time\", col(\"Taxi_Out_Time\").cast(FloatType()))\n","df = df.withColumn(\"Takeoff_Time\", col(\"Takeoff_Time\").cast(FloatType()))\n","df = df.withColumn(\"Landing_Time\", col(\"Landing_Time\").cast(FloatType()))\n","df = df.withColumn(\"Taxi_In_Time\", col(\"Taxi_In_Time\").cast(FloatType()))\n","df = df.withColumn(\"Scheduled_Arrival_Time\", col(\"Scheduled_Arrival_Time\").cast(IntegerType()))\n","df = df.withColumn(\"Actual_Arrival_Time\", col(\"Actual_Arrival_Time\").cast(IntegerType()))\n","df = df.withColumn(\"Arrival_Delay_Minutes\", col(\"Arrival_Delay_Minutes\").cast(IntegerType()))\n","df = df.withColumn(\"Flight_Cancelled\", col(\"Flight_Cancelled\").cast(IntegerType()))\n","df = df.withColumn(\"Flight_Diverted\", col(\"Flight_Diverted\").cast(IntegerType()))\n","df = df.withColumn(\"Scheduled_Flight_Duration\", col(\"Scheduled_Flight_Duration\").cast(FloatType()))\n","df = df.withColumn(\"Actual_Flight_Duration\", col(\"Actual_Flight_Duration\").cast(FloatType()))\n","df = df.withColumn(\"Airborne_Time\", col(\"Airborne_Time\").cast(FloatType()))\n","df = df.withColumn(\"Flight_Distance\", col(\"Flight_Distance\").cast(FloatType()))\n","df = df.withColumn(\"Carrier_Delay_Minutes\", col(\"Carrier_Delay_Minutes\").cast(FloatType()))\n","df = df.withColumn(\"Weather_Delay_Minutes\", col(\"Weather_Delay_Minutes\").cast(FloatType()))\n","df = df.withColumn(\"NAS_Delay_Minutes\", col(\"NAS_Delay_Minutes\").cast(FloatType()))\n","df = df.withColumn(\"Security_Delay_Minutes\", col(\"Security_Delay_Minutes\").cast(FloatType()))\n","df = df.withColumn(\"Late_Aircraft_Delay_Minutes\", col(\"Late_Aircraft_Delay_Minutes\").cast(FloatType()))\n","df = df.withColumn(\"latitude_orig\", col(\"latitude_orig\").cast(FloatType()))\n","df = df.withColumn(\"longitude_orig\", col(\"longitude_orig\").cast(FloatType()))\n","df = df.withColumn(\"latitude_dest\", col(\"latitude_dest\").cast(FloatType()))\n","df = df.withColumn(\"longitude_dest\", col(\"longitude_dest\").cast(FloatType()))"],"metadata":{"id":"9UDZUJJz1yzY"},"execution_count":null,"outputs":[]}]}